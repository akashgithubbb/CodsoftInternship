{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlLdszvUrKHq"
      },
      "outputs": [],
      "source": [
        "# Install the required libraries if you haven't already\n",
        "# pip install pandas scikit-learn xgboost\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# dataset\n",
        "\n",
        "data = pd.read_csv('Churn_Modelling.csv')\n",
        "\n",
        "# For the sake of illustration, let's create a dummy dataset\n",
        "data = pd.DataFrame({\n",
        "    'CustomerID': [1, 2, 3, 4, 5],\n",
        "    'UsageDuration': [100, 150, 80, 200, 120],\n",
        "    'MonthlyFee': [50, 60, 40, 70, 55],\n",
        "    'Age': [25, 30, 22, 35, 28],\n",
        "    'Churn': [0, 1, 0, 1, 0]  # 0: No churn, 1: Churn\n",
        "})\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(['CustomerID', 'Churn'], axis=1)\n",
        "y = data['Churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Train Logistic Regression\n",
        "logistic_regression = LogisticRegression(random_state=42)\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = logistic_regression.predict(X_test_scaled)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train_scaled, y_train)\n",
        "y_pred_xgb = xgb_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    confusion = confusion_matrix(y_true, y_pred)\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    print(f'\\n{name} Model:')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print('Confusion Matrix:\\n', confusion)\n",
        "    print('Classification Report:\\n', report)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "evaluate_model('Random Forest', y_test, y_pred_rf)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "evaluate_model('Logistic Regression', y_test, y_pred_lr)\n",
        "\n",
        "# Evaluate XGBoost model\n",
        "evaluate_model('XGBoost', y_test, y_pred_xgb)\n"
      ]
    }
  ]
}